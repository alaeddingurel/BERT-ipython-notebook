{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of BERT Predictions",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkTLZ3I4_7c_",
        "colab_type": "text"
      },
      "source": [
        "# Sentence classification - BERT finetuning -  TPU\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\" >\n",
        " <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wtjs1QDb3DX",
        "colab_type": "text"
      },
      "source": [
        "**BERT**, or **B**idirectional **E**mbedding **R**epresentations from **T**ransformers, is a new method of pre-training language representations which obtains state-of-the-art results on a wide array of Natural Language Processing (NLP) tasks. The academic paper can be found here: https://arxiv.org/abs/1810.04805.\n",
        "\n",
        "This Colab demonstates using a free Colab Cloud TPU to fine-tune sentence and sentence-pair classification tasks built on top of pretrained BERT models.\n",
        "\n",
        "**Note:**  You will need a GCP (Google Compute Engine) account and a GCS (Google Cloud \n",
        "Storage) bucket for this Colab to run.\n",
        "\n",
        "Please follow the [Google Cloud TPU quickstart](https://cloud.google.com/tpu/docs/quickstart) for how to create GCP account and GCS bucket. You have [$300 free credit](https://cloud.google.com/free/) to get started with any GCP product. You can learn more about Cloud TPU at https://cloud.google.com/tpu/docs.\n",
        "\n",
        "Once you finish the setup, let's start!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycHMh-bhC-vX",
        "colab_type": "text"
      },
      "source": [
        "**Firstly**, we need to set up Colab TPU running environment, verify a TPU device is succesfully connected and upload credentials to TPU for GCS bucket usage."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "191zq3ZErihP",
        "colab_type": "code",
        "outputId": "c284303d-1d92-4f7e-cce9-361f10571224",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "source": [
        "import datetime\n",
        "import json\n",
        "import os\n",
        "import pprint\n",
        "import random\n",
        "import string\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "\n",
        "assert 'COLAB_TPU_ADDR' in os.environ, 'ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!'\n",
        "TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "print('TPU address is', TPU_ADDRESS)\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "with tf.Session(TPU_ADDRESS) as session:\n",
        "  print('TPU devices:')\n",
        "  pprint.pprint(session.list_devices())\n",
        "\n",
        "  # Upload credentials to TPU.\n",
        "  with open('/content/adc.json', 'r') as f:\n",
        "    auth_info = json.load(f)\n",
        "  tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n",
        "  # Now credentials are set for all future sessions on this TPU."
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TPU address is grpc://10.104.37.58:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0802 07:51:22.676072 140257710847872 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "TPU devices:\n",
            "[_DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 9859838020152805601),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 11801699439757522170),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 17509246291820947546),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 2814200446972778295),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 9251293896013119029),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 5181952564651276190),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 15803278180543265295),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 16716905167322649165),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 15631505610979133869),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 16257752975412102291),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 4621927577156578645)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUBP35oCDmbF",
        "colab_type": "text"
      },
      "source": [
        "**Secondly**, prepare and import BERT modules."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wzwke0sxS6W",
        "colab_type": "code",
        "outputId": "cbfbf542-2eee-484d-ecb8-dbb78d5efe68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "import sys\n",
        "\n",
        "!test -d bert_repo || git clone https://github.com/google-research/bert bert_repo\n",
        "if not 'bert_repo' in sys.path:\n",
        "  sys.path += ['bert_repo']"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'bert_repo'...\n",
            "remote: Enumerating objects: 333, done.\u001b[K\n",
            "remote: Total 333 (delta 0), reused 0 (delta 0), pack-reused 333\u001b[K\n",
            "Receiving objects: 100% (333/333), 279.30 KiB | 3.83 MiB/s, done.\n",
            "Resolving deltas: 100% (183/183), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRu1aKO1D7-Z",
        "colab_type": "text"
      },
      "source": [
        "**Thirdly**, prepare for training:\n",
        "\n",
        "*  Specify task and download training data.\n",
        "*  Specify BERT pretrained model\n",
        "*  Specify GS bucket, create output directory for model checkpoints and eval results.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEPCCjSriekD",
        "colab_type": "code",
        "outputId": "74872090-05a2-4877-f60e-90a9fe791e53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')\n",
        "!ls \"/content/drive/My Drive\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            " 19072019-Alaeddin.gdoc\n",
            " 20180801_theHindu_AgreedByAll.gsheet\n",
            " 20180901_theIndianExpress_AgreedByAll.xlsx\n",
            " 20190319_fd_Error_Analysis_on_India_Data.gsheet\n",
            " 26072019-Alaeddin.gdoc\n",
            " AlaeddinSelcukGurelReport.gdoc\n",
            " allbertpredictions.csv\n",
            " Assel_Guncel_Program.gsheet\n",
            " assignment1-comp429.gdoc\n",
            " assignment1-comp429.pdf\n",
            "'batch1 (1).json'\n",
            " batch1.json\n",
            " batch1_updated.json\n",
            "'batch2 (1).json'\n",
            " batch2.json\n",
            " batch2_updated.json\n",
            "'batch3 (1).json'\n",
            " batch3.json\n",
            " batch3_updated.json\n",
            "'batch4 (1).json'\n",
            " batch4.json\n",
            " batch4_updated.json\n",
            "'batch5 (1).json'\n",
            " batch5.json\n",
            " batch5_updated.json\n",
            "'BBC Monitoring & Reuters.gdoc'\n",
            " bertdocumentpredictions.csv\n",
            " bertdocumentpredictionsurl.csv\n",
            " BERT.gdoc\n",
            "'Book report (1).gslides'\n",
            "'Book report.gslides'\n",
            "'Chinese NLP.gdoc'\n",
            " CNN.gdoc\n",
            "'Colab Notebooks'\n",
            " data.csv\n",
            "'Decision Making in Perl.gslides'\n",
            " dockerubuntu.zip\n",
            "'Event Sentence Identification in News.gslides'\n",
            " Ezgi_20181024-newindianexpress_sentence_classification.gsheet\n",
            " Ezgi_20181024-newindianexpress_sentence_classification.xlsx\n",
            " ezgi-eylem_20180711_indianexpress-Multievent.gsheet\n",
            " ezgi-eylem_20180801_thehindu-MultiEvent.gsheet\n",
            "'Getting started.pdf'\n",
            "'GRU - LSTM.gdoc'\n",
            " learning-agreement-Alaeddin.gdoc\n",
            "\"Makarov's IE annotation Analysis.gdoc\"\n",
            " ManytoOne.png\n",
            " OnetoMany.png\n",
            "'OUT OF CONTROL.gdoc'\n",
            " pelin-enes_20180919_newindianexpress-MultiEvent.gsheet\n",
            " pelin-selim_20180711_indianexpress-MultiEvent.gsheet\n",
            " Rapor.gdoc\n",
            " Report\n",
            "'Report (1).gdoc'\n",
            " Report.gdoc\n",
            "'Resume (1).gdoc'\n",
            " Resume.gdoc\n",
            " RNN.png\n",
            " samplesforbert\n",
            "'Science project (1).gslides'\n",
            "'Science project.gslides'\n",
            " sercan-gizem_20180711_indianexpress-MultiEvent.gsheet\n",
            " Subjects.gdoc\n",
            "'text (1).json'\n",
            " text.json\n",
            " thesis\n",
            " TODO.gdoc\n",
            " tugbahocapaper\n",
            "'Untitled document (1).gdoc'\n",
            "'Untitled document (2).gdoc'\n",
            "'Untitled document (3).gdoc'\n",
            "'Untitled document (4).gdoc'\n",
            "'Untitled document (5).gdoc'\n",
            "'Untitled document (6).gdoc'\n",
            "'Untitled document.gdoc'\n",
            "'Untitled presentation (1).gslides'\n",
            "'Untitled presentation (2).gslides'\n",
            "'Untitled presentation.gslides'\n",
            "'Untitled spreadsheet.gsheet'\n",
            " Word2vec-GLOVE-Bert-FastText.gdoc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYkaAlJNfhul",
        "colab_type": "code",
        "outputId": "47a5a654-f69a-44bc-e5f1-fe1a31c67acb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "TASK = 'sentence_classification' #@param {type:\"string\"}\n",
        "#assert TASK in ('MRPC', 'CoLA'), 'Only (MRPC, CoLA) are demonstrated here.'\n",
        "# Download glue data.\n",
        "#! test -d download_glue_repo || git clone https://gist.github.com/60c2bdb54d156a41194446737ce03e2e.git download_glue_repo\n",
        "#!python download_glue_repo/download_glue_data.py --data_dir='glue_data' --tasks=$TASK\n",
        "TASK_DATA_DIR = \"/content/drive/'My Drive'/samplesforbert\" #@param {type:\"string\"}\n",
        "print('***** Task data directory: {} *****'.format(TASK_DATA_DIR))\n",
        "#!ls /content/drive/'My Drive'/thesis/data\n",
        "!ls $TASK_DATA_DIR\n",
        "\n",
        "# Available pretrained model checkpoints:\n",
        "#   uncased_L-12_H-768_A-12: uncased BERT base model\n",
        "#   uncased_L-24_H-1024_A-16: uncased BERT large model\n",
        "#   cased_L-12_H-768_A-12: cased BERT large model\n",
        "BERT_MODEL = 'uncased_L-12_H-768_A-12' #@param {type:\"string\"}\n",
        "BERT_PRETRAINED_DIR = 'gs://cloud-tpu-checkpoints/bert/' + BERT_MODEL\n",
        "print('***** BERT pretrained directory: {} *****'.format(BERT_PRETRAINED_DIR))\n",
        "!gsutil ls $BERT_PRETRAINED_DIR\n",
        "\n",
        "BUCKET = 'alaeddinselcukgurel' #@param {type:\"string\"}\n",
        "assert BUCKET, 'Must specify an existing GCS bucket name'\n",
        "OUTPUT_DIR = 'gs://{}/bert/models/{}'.format(BUCKET, TASK)\n",
        "tf.gfile.MakeDirs(OUTPUT_DIR)\n",
        "print('***** Model output directory: {} *****'.format(OUTPUT_DIR))\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Task data directory: /content/drive/'My Drive'/samplesforbert *****\n",
            "'guardian_bert (1).gsheet'   guardian_sample_with_annotations.csv\n",
            " guardian_bert.csv\t     sentence_predictions.csv\n",
            " guardian_bert.gsheet\n",
            "***** BERT pretrained directory: gs://cloud-tpu-checkpoints/bert/uncased_L-12_H-768_A-12 *****\n",
            "gs://cloud-tpu-checkpoints/bert/uncased_L-12_H-768_A-12/bert_config.json\n",
            "gs://cloud-tpu-checkpoints/bert/uncased_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001\n",
            "gs://cloud-tpu-checkpoints/bert/uncased_L-12_H-768_A-12/bert_model.ckpt.index\n",
            "gs://cloud-tpu-checkpoints/bert/uncased_L-12_H-768_A-12/bert_model.ckpt.meta\n",
            "gs://cloud-tpu-checkpoints/bert/uncased_L-12_H-768_A-12/checkpoint\n",
            "gs://cloud-tpu-checkpoints/bert/uncased_L-12_H-768_A-12/vocab.txt\n",
            "***** Model output directory: gs://alaeddinselcukgurel/bert/models/sentence_classification *****\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hcpfl4N2EdOk",
        "colab_type": "text"
      },
      "source": [
        "**Now, let's play!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uu2dQ_TId-uH",
        "colab_type": "code",
        "outputId": "84fcc72b-7e30-4f38-8257-ecbcd681438d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "# Setup task specific model and TPU running config.\n",
        "\n",
        "import modeling\n",
        "import optimization\n",
        "import run_classifier\n",
        "import tokenization\n",
        "\n",
        "\n",
        "# Model Hyper Parameters\n",
        "TRAIN_BATCH_SIZE = 32\n",
        "EVAL_BATCH_SIZE = 8\n",
        "LEARNING_RATE = 2e-5\n",
        "NUM_TRAIN_EPOCHS = 3.0\n",
        "WARMUP_PROPORTION = 0.1\n",
        "MAX_SEQ_LENGTH = 256\n",
        "# Model configs\n",
        "SAVE_CHECKPOINTS_STEPS = 1000\n",
        "ITERATIONS_PER_LOOP = 1000\n",
        "NUM_TPU_CORES = 8\n",
        "VOCAB_FILE = os.path.join(BERT_PRETRAINED_DIR, 'vocab.txt')\n",
        "CONFIG_FILE = os.path.join(BERT_PRETRAINED_DIR, 'bert_config.json')\n",
        "INIT_CHECKPOINT = os.path.join(BERT_PRETRAINED_DIR, 'bert_model.ckpt')\n",
        "DO_LOWER_CASE = BERT_MODEL.startswith('uncased')\n",
        "\n",
        "#processors = {\n",
        " # \"cola\": run_classifier.ColaProcessor,\n",
        " # \"mnli\": run_classifier.MnliProcessor,\n",
        " # \"mrpc\": run_classifier.MrpcProcessor,\n",
        "#}\n",
        "#processor = processors[TASK.lower()]()\n",
        "#label_list = processor.get_labels()\n",
        "tokenizer = tokenization.FullTokenizer(vocab_file=VOCAB_FILE, do_lower_case=DO_LOWER_CASE)\n",
        "\n",
        "tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TPU_ADDRESS)\n",
        "run_config = tf.contrib.tpu.RunConfig(\n",
        "    cluster=tpu_cluster_resolver,\n",
        "    model_dir=OUTPUT_DIR,\n",
        "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS,\n",
        "    keep_checkpoint_max=SAVE_CHECKPOINTS_STEPS,\n",
        "    tpu_config=tf.contrib.tpu.TPUConfig(\n",
        "        iterations_per_loop=ITERATIONS_PER_LOOP,\n",
        "        num_shards=NUM_TPU_CORES,\n",
        "        per_host_input_for_training=tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2))\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0802 07:52:17.407781 140257710847872 deprecation_wrapper.py:119] From bert_repo/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0802 07:52:17.425853 140257710847872 deprecation_wrapper.py:119] From bert_repo/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJJmhiH-lauz",
        "colab_type": "text"
      },
      "source": [
        "**Csv file reader**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oh_tbqIwjli7",
        "colab_type": "code",
        "outputId": "afe42666-829c-4901-e027-c90b8effeb0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "batch_no = '5'\n",
        "import pandas as pd\n",
        "TASK_DATA_DIR_EDITED = '/content/drive/My Drive/thesis/emwdocumentbert'\n",
        "#get training data\n",
        "#data_file_name = \"Newindianexpress_sentences_adjudicated_train.csv\"\n",
        "data_file_name = \"/Batch_\" + batch_no + \"/train_\" + batch_no + \".csv\"\n",
        "train = pd.read_csv(TASK_DATA_DIR_EDITED + '/' + data_file_name, header=0)\n",
        "\n",
        "import numpy as np\n",
        "list(train)\n",
        "nrow,ncol=train.shape\n",
        "\n",
        "#get validation data\n",
        "#data_file_name = \"Newindianexpress_sentences_adjudicated_val.csv\"\n",
        "data_file_name = \"/Batch_\" + batch_no + \"/validation_\" + batch_no + \".csv\"\n",
        "val = pd.read_csv(TASK_DATA_DIR_EDITED + '/' + data_file_name, header=0)\n",
        "list(val)\n",
        "vnrow,vncol=val.shape\n",
        "vnrow\n",
        "\n",
        "#get eval (test) data\n",
        "#data_file_name = \"Newindianexpress_sentences_adjudicated_test.csv\"\n",
        "data_file_name = \"/Batch_\" + batch_no + \"/test_\" + batch_no + \".csv\"\n",
        "eval = pd.read_csv(TASK_DATA_DIR_EDITED + '/' + data_file_name, header=0)\n",
        "list(eval)\n",
        "enrow,encol=eval.shape\n",
        "enrow\n",
        "\n",
        "list(train)\n",
        "train_text = train[\"text\"]\n",
        "print(len(train_text))\n",
        "\n",
        "none_protest = train[train[\"label\"] == 0]\n",
        "none_protest_text = none_protest[\"text\"]\n",
        "print(len(none_protest_text))\n",
        "\n",
        "happened = train[train[\"label\"] == 1]\n",
        "happened_text = happened[\"text\"]\n",
        "print(len(happened_text))\n",
        "\n",
        "planned = train[train[\"label\"] == 2]\n",
        "planned_text = planned[\"text\"]\n",
        "print(len(planned_text))\n",
        "\n",
        "assert len(planned_text) + len(happened_text) + len(none_protest_text) == len(train_text)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3579\n",
            "2723\n",
            "856\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcI2THlZBXHK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzoJhjJE34Dy",
        "colab_type": "code",
        "outputId": "0ff5d62c-c6a1-4b36-8a20-8fededd2aed0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(train.loc[train.label == 2])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n07J3Uu6pQd6",
        "colab_type": "code",
        "outputId": "a56693bd-9c75-473c-c652-0ae0c19abb7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# used to calculate metrics (in bert)\n",
        "val.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(457, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oljeEJybpLUc",
        "colab_type": "code",
        "outputId": "c0ae4c9c-1629-4b2d-cedc-e2abef56d227",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# used to predict and calculate custom metrics (f1 and mcc)\n",
        "eval.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(687, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgCE5mdwuz5u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_COLUMN = 'text'\n",
        "LABEL_COLUMN = 'label'\n",
        "# label_list is the list of labels, i.e. True, False or 0, 1 or 'dog', 'cat'\n",
        "label_list = [0, 1]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ltjnv_N9iLXP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train_examples = processor.get_train_examples(TASK_DATA_DIR)\n",
        "# customize get_train_examples:\n",
        "# Use the InputExample class from BERT's run_classifier code to create examples from the data\n",
        "train_examples = train.apply(lambda x: run_classifier.InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this example\n",
        "                                                                   text_a = x[DATA_COLUMN], \n",
        "                                                                   text_b = None, \n",
        "                                                                   label = x[LABEL_COLUMN]), axis = 1)\n",
        "\n",
        "val_examples = val.apply(lambda x: run_classifier.InputExample(guid=None, \n",
        "                                                                   text_a = x[DATA_COLUMN], \n",
        "                                                                   text_b = None, \n",
        "                                                                   label = x[LABEL_COLUMN]), axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlxHz2xwgtwC",
        "colab_type": "code",
        "outputId": "f984e749-506c-4eab-dc7c-3cd396ccd252",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "num_train_steps = int(\n",
        "    len(train_examples) / TRAIN_BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
        "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
        "\n",
        "model_fn = run_classifier.model_fn_builder(\n",
        "    bert_config=modeling.BertConfig.from_json_file(CONFIG_FILE),\n",
        "    num_labels=len(label_list),\n",
        "    init_checkpoint=INIT_CHECKPOINT,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    num_train_steps=num_train_steps,\n",
        "    num_warmup_steps=num_warmup_steps,\n",
        "    use_tpu=True,\n",
        "    use_one_hot_embeddings=True)\n",
        "\n",
        "estimator = tf.contrib.tpu.TPUEstimator(\n",
        "    use_tpu=True,\n",
        "    model_fn=model_fn,\n",
        "    config=run_config,\n",
        "    train_batch_size=TRAIN_BATCH_SIZE,\n",
        "    eval_batch_size=EVAL_BATCH_SIZE,\n",
        "    predict_batch_size=EVAL_BATCH_SIZE)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0802 07:52:22.537038 140257710847872 estimator.py:1984] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f90038f1ea0>) includes params argument, but params are not passed to Estimator.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5U_c8s2AvhgL",
        "colab_type": "code",
        "outputId": "c624cdbb-5580-4246-eed8-0ca9651274e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "# Train the model.\n",
        "#print('MRPC/CoLA on BERT base model normally takes about 2-3 minutes. Please wait...')\n",
        "train_features = run_classifier.convert_examples_to_features(\n",
        "    train_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "print('***** Started training at {} *****'.format(datetime.datetime.now()))\n",
        "print('  Num examples = {}'.format(len(train_examples)))\n",
        "print('  Batch size = {}'.format(TRAIN_BATCH_SIZE))\n",
        "tf.compat.v1.logging.info(\"  Num steps = %d\", num_train_steps)\n",
        "train_input_fn = run_classifier.input_fn_builder(\n",
        "    features=train_features,\n",
        "    seq_length=MAX_SEQ_LENGTH,\n",
        "    is_training=True,\n",
        "    drop_remainder=True)\n",
        "estimator.train(input_fn=train_input_fn, max_steps=500)\n",
        "print('***** Finished training at {} *****'.format(datetime.datetime.now()))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Started training at 2019-08-02 07:52:55.883094 *****\n",
            "  Num examples = 3579\n",
            "  Batch size = 32\n",
            "***** Finished training at 2019-08-02 07:52:57.155583 *****\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoXRtSPZvdiS",
        "colab_type": "code",
        "outputId": "fda9c0c7-bf55-4644-b9da-379e337ab909",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 732
        }
      },
      "source": [
        "# Eval the model.\n",
        "eval_features = run_classifier.convert_examples_to_features(val_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "#eval_examples = processor.get_dev_examples(TASK_DATA_DIR)\n",
        "#eval_features = run_classifier.convert_examples_to_features(\n",
        "#    val_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "print('***** Started evaluation at {} *****'.format(datetime.datetime.now()))\n",
        "print('  Num examples = {}'.format(len(val_examples)))\n",
        "print('  Batch size = {}'.format(EVAL_BATCH_SIZE))\n",
        "# Eval will be slightly WRONG on the TPU because it will truncate\n",
        "# the last batch.\n",
        "eval_steps = int(len(val_examples) / EVAL_BATCH_SIZE)\n",
        "eval_input_fn = run_classifier.input_fn_builder(\n",
        "    features=eval_features,\n",
        "    seq_length=MAX_SEQ_LENGTH,\n",
        "    is_training=False,\n",
        "    drop_remainder=True)\n",
        "\n",
        "''' \n",
        "#Buna gerek yok. Direkt trainingden restore ediyor zaten.\n",
        "TRAINING_CHECKPOINT = os.path.join(OUTPUT_DIR, 'model.ckpt-500')\n",
        "model_fn2 = run_classifier.model_fn_builder(\n",
        "    bert_config=modeling.BertConfig.from_json_file(CONFIG_FILE),\n",
        "    num_labels=len(label_list),\n",
        "    init_checkpoint=TRAINING_CHECKPOINT,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    num_train_steps=num_train_steps,\n",
        "    num_warmup_steps=num_warmup_steps,\n",
        "    use_tpu=True,\n",
        "    use_one_hot_embeddings=True)\n",
        "\n",
        "estimator2 = tf.contrib.tpu.TPUEstimator(\n",
        "    use_tpu=True,\n",
        "    model_fn=model_fn2,\n",
        "    config=run_config,\n",
        "    train_batch_size=TRAIN_BATCH_SIZE,\n",
        "    eval_batch_size=EVAL_BATCH_SIZE,\n",
        "    predict_batch_size=EVAL_BATCH_SIZE)\n",
        "'''\n",
        "\n",
        "result = estimator.evaluate(input_fn=eval_input_fn, steps=eval_steps)\n",
        "print('***** Finished evaluation at {} *****'.format(datetime.datetime.now()))\n",
        "output_eval_file = os.path.join(OUTPUT_DIR, \"eval_results.txt\")\n",
        "with tf.io.gfile.GFile(output_eval_file, \"w\") as writer:\n",
        "  print(\"***** Eval results *****\")\n",
        "  for key in sorted(result.keys()):\n",
        "    print('  {} = {}'.format(key, str(result[key])))\n",
        "    writer.write(\"%s = %s\\n\" % (key, str(result[key])))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Started evaluation at 2019-08-02 07:53:00.763223 *****\n",
            "  Num examples = 457\n",
            "  Batch size = 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0802 07:53:01.491776 140257710847872 deprecation_wrapper.py:119] From bert_repo/modeling.py:171: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0802 07:53:01.497095 140257710847872 deprecation_wrapper.py:119] From bert_repo/modeling.py:409: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "W0802 07:53:01.553837 140257710847872 deprecation_wrapper.py:119] From bert_repo/modeling.py:490: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
            "\n",
            "W0802 07:53:01.624007 140257710847872 deprecation.py:323] From bert_repo/modeling.py:671: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "W0802 07:53:05.157678 140257710847872 deprecation_wrapper.py:119] From bert_repo/run_classifier.py:647: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "W0802 07:53:05.473587 140257710847872 deprecation_wrapper.py:119] From bert_repo/run_classifier.py:656: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n",
            "\n",
            "W0802 07:53:06.861617 140257710847872 deprecation_wrapper.py:119] From bert_repo/run_classifier.py:657: The name tf.train.Scaffold is deprecated. Please use tf.compat.v1.train.Scaffold instead.\n",
            "\n",
            "W0802 07:53:06.864730 140257710847872 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:3154: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "W0802 07:53:07.258036 140257710847872 deprecation_wrapper.py:119] From bert_repo/run_classifier.py:686: The name tf.metrics.accuracy is deprecated. Please use tf.compat.v1.metrics.accuracy instead.\n",
            "\n",
            "W0802 07:53:07.279139 140257710847872 deprecation_wrapper.py:119] From bert_repo/run_classifier.py:688: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.\n",
            "\n",
            "W0802 07:53:08.527741 140257710847872 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0802 07:53:09.000638 140257710847872 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "W0802 07:53:26.710747 140257710847872 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:792: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Variable.assign which has equivalent behavior in 2.X.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "***** Finished evaluation at 2019-08-02 07:53:42.388128 *****\n",
            "***** Eval results *****\n",
            "  eval_accuracy = 0.9232456\n",
            "  eval_loss = 0.37256804\n",
            "  global_step = 500\n",
            "  loss = 0.10518332\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNwtgu6KtbCd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PREDICT_BATCH_SIZE = 8\n",
        "def getPrediction(in_sentences):\n",
        "  labels = [\"0\", \"1\"]\n",
        "  input_examples = [run_classifier.InputExample(guid=\"\", text_a = x, text_b = None, label = 0) for x in in_sentences] # here, \"\" is just a dummy label\n",
        "  input_features = run_classifier.convert_examples_to_features(input_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "  predict_input_fn = run_classifier.input_fn_builder(features=input_features, seq_length=MAX_SEQ_LENGTH, is_training=False, drop_remainder=True)\n",
        "  predictions = estimator.predict(predict_input_fn)\n",
        "  return predictions\n",
        " \n",
        "  #return [(sentence, prediction['probabilities'], labels[prediction['labels']]) for sentence, prediction in zip(in_sentences, predictions)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1FIcezhUmVk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_sentences = eval['text']\n",
        "result = getPrediction(test_sent)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gm96aFvqUuYJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e46ada5e-8472-4848-b5e1-cb5655f8de0f"
      },
      "source": [
        "eval.columns"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'id', 'label', 'text', 'url'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9z6Rnz1bsqMu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "num_actual_predict_examples = len(test_sentences)\n",
        "output_predict_file = os.path.join(OUTPUT_DIR, \"test_results.tsv\")\n",
        "pred_labels = []\n",
        "pred_probs = []\n",
        "with tf.io.gfile.GFile(output_predict_file, \"w\") as writer:\n",
        "  num_written_lines = 0\n",
        "  tf.logging.info(\"***** Predict results *****\")\n",
        "  for (i, prediction) in enumerate(result):\n",
        "    probabilities = prediction[\"probabilities\"]\n",
        "    probabilitieslist = list(probabilities)\n",
        "    pred_probs.append(probabilitieslist)\n",
        "    if i >= num_actual_predict_examples:\n",
        "      break\n",
        "    label = str(probabilitieslist.index(max(probabilities))) # 0 1 or 2\n",
        "    pred_labels.append(label)\n",
        "    output_line = label + \"\\t\" + \"\\t\".join(\n",
        "        str(class_probability)\n",
        "        for class_probability in probabilities) + \"\\t\"+ test_sentences[i] + \"\\n\" \n",
        "    writer.write(output_line)\n",
        "    if label == \"2\": print(output_line)\n",
        "    num_written_lines += 1\n",
        "#assert num_written_lines == num_actual_predict_examples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CB7-UzEqdDzM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_labels = eval[LABEL_COLUMN].tolist()\n",
        "pred_labels_int = [int(i) for i in pred_labels]\n",
        "pred_probs_float = [[float(i) for i in a] for a in pred_probs]\n",
        "\n",
        "assert len(test_labels) == len(pred_labels_int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxP1eAfQgvFD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyFL6TnyEpcP",
        "colab_type": "code",
        "outputId": "28d1a59b-9ab5-40b7-a9c1-3f5f6fa82547",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "import sklearn\n",
        "f1_macro = sklearn.metrics.f1_score(test_labels, pred_labels_int, average = \"macro\")\n",
        "mcc = sklearn.metrics.matthews_corrcoef(test_labels, pred_labels_int)\n",
        "accuracy = sklearn.metrics.accuracy_score(test_labels, pred_labels_int)\n",
        "#log_loss = sklearn.metrics.log_loss(test_labels, pred_probs_float)\n",
        "print(f1_macro)\n",
        "print(mcc)\n",
        "print(accuracy)\n",
        "print(sklearn.metrics.precision_score(test_labels, pred_labels_int))\n",
        "print(sklearn.metrics.recall_score(test_labels, pred_labels_int))\n",
        "\n",
        "#print(log_loss)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9082135131696145\n",
            "0.8191498477728089\n",
            "0.9388646288209607\n",
            "0.9117647058823529\n",
            "0.8051948051948052\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocXik_T9VpyA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "nltk.download('popular')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4L-M9Y4VZw_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "7c8ebfbd-1e58-44be-8193-73973afe6c35"
      },
      "source": [
        "#INDIA EVALUATION TO SENTENCES\n",
        "texts_and_urls = pd.DataFrame(columns= [\"url\", \"sentence\"])\n",
        "for idx, doc in eval.iterrows():\n",
        "  url = doc.url\n",
        "  for elem in nltk.sent_tokenize(doc.text):\n",
        "    texts_and_urls = texts_and_urls.append({\"url\": url, \"sentence\": elem}, ignore_index=True)\n",
        "\"\"\"  tokenized_sentences = nltk.sent_tokenize(doc)\n",
        "  tokenized_results = getPrediction(tokenized_sentences)\n",
        "  result_list.append(tokenized_results)\"\"\""
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'  tokenized_sentences = nltk.sent_tokenize(doc)\\n  tokenized_results = getPrediction(tokenized_sentences)\\n  result_list.append(tokenized_results)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSxjeBPWVm6v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "17e1f4eb-8bc7-4ca5-c98c-7381e5607c50"
      },
      "source": [
        "len(texts_and_urls)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9575"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1E1BubsWFKf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#INDIA EVALUATION SENTENCES PREDICTION RESULT\n",
        "result = getPrediction(texts_and_urls.sentence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErZOH2TaWQcZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#INDIA SENTENCE PREDICTION\n",
        "num_actual_predict_examples = len(texts_and_urls)\n",
        "output_predict_file = os.path.join(OUTPUT_DIR, \"test_results.tsv\")\n",
        "pred_labels = []\n",
        "pred_probs = []\n",
        "with tf.io.gfile.GFile(output_predict_file, \"w\") as writer:\n",
        "  num_written_lines = 0\n",
        "  tf.logging.info(\"***** Predict results *****\")\n",
        "  for (i, prediction) in enumerate(result):\n",
        "    probabilities = prediction[\"probabilities\"]\n",
        "    probabilitieslist = list(probabilities)\n",
        "    pred_probs.append(probabilitieslist)\n",
        "    if i >= num_actual_predict_examples:\n",
        "      break\n",
        "    label = str(probabilitieslist.index(max(probabilities))) # 0 1 or 2\n",
        "    pred_labels.append(label)\n",
        "#   output_line = label + \"\\t\" + \"\\t\".join(\n",
        "#       str(class_probability)\n",
        "#       for class_probability in probabilities) + \"\\t\"+ test_sent[i] + \"\\n\" \n",
        "#   writer.write(output_line)\n",
        "#   if label == \"2\": print(output_line)\n",
        "    num_written_lines += 1\n",
        "#assert num_written_lines == num_actual_predict_examples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYT1DjvXWfoh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "772aaff3-2e93-4a2f-c823-b86f810b328c"
      },
      "source": [
        "len(pred_labels)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9575"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JYi_jiAWjzL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#INDIA ADD PREDICTIONS TO DF\n",
        "texts_and_urls['bert_sentence_pred'] = pred_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hHHQRhuW0mI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "45508088-5106-44d6-bfc7-e59c234256cd"
      },
      "source": [
        "texts_and_urls.head()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>url</th>\n",
              "      <th>sentence</th>\n",
              "      <th>bert_sentence_pred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://timesofindia.indiatimes.com/city/benga...</td>\n",
              "      <td>HDMC man's wife chained, assaulted for dowry\\n...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://timesofindia.indiatimes.com/city/benga...</td>\n",
              "      <td>the woman was admitted to the kims hospital in...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://timesofindia.indiatimes.com/city/benga...</td>\n",
              "      <td>the victim, identified as lakshmi anantha taga...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://timesofindia.indiatimes.com/city/benga...</td>\n",
              "      <td>on a tip-off, the police reached the spot and ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://timesofindia.indiatimes.com/city/benga...</td>\n",
              "      <td>the police source revealed that lakshmi was ma...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 url  ... bert_sentence_pred\n",
              "0  https://timesofindia.indiatimes.com/city/benga...  ...                  0\n",
              "1  https://timesofindia.indiatimes.com/city/benga...  ...                  0\n",
              "2  https://timesofindia.indiatimes.com/city/benga...  ...                  0\n",
              "3  https://timesofindia.indiatimes.com/city/benga...  ...                  0\n",
              "4  https://timesofindia.indiatimes.com/city/benga...  ...                  0\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbs--J60BzKM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PREDICT_BATCH_SIZE = 8\n",
        "def getPrediction(in_sentences):\n",
        "  labels = [\"0\", \"1\"]\n",
        "  input_examples = [run_classifier.InputExample(guid=\"\", text_a = x, text_b = None, label = 0) for x in in_sentences] # here, \"\" is just a dummy label\n",
        "  input_features = run_classifier.convert_examples_to_features(input_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "  predict_input_fn = run_classifier.input_fn_builder(features=input_features, seq_length=MAX_SEQ_LENGTH, is_training=False, drop_remainder=True)\n",
        "  predictions = estimator.predict(predict_input_fn)\n",
        "  return predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBtvU1rVCEO-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVc_ycyBmcAG",
        "colab_type": "code",
        "outputId": "3901ef59-33ae-4248-c498-966beb65929a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "num_train_steps = int(\n",
        "    len(train_examples) / TRAIN_BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
        "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
        "\n",
        "model_fn = run_classifier.model_fn_builder(\n",
        "    bert_config=modeling.BertConfig.from_json_file(CONFIG_FILE),\n",
        "    num_labels=len(label_list),\n",
        "    init_checkpoint=INIT_CHECKPOINT,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    num_train_steps=num_train_steps,\n",
        "    num_warmup_steps=num_warmup_steps,\n",
        "    use_tpu=True,\n",
        "    use_one_hot_embeddings=True)\n",
        "\n",
        "estimator = tf.contrib.tpu.TPUEstimator(\n",
        "    use_tpu=True,\n",
        "    model_fn=model_fn,\n",
        "    config=run_config,\n",
        "    train_batch_size=TRAIN_BATCH_SIZE,\n",
        "    eval_batch_size=EVAL_BATCH_SIZE,\n",
        "    predict_batch_size=EVAL_BATCH_SIZE)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0731 12:23:53.909987 139773629339520 estimator.py:1984] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f1f48cb6c80>) includes params argument, but params are not passed to Estimator.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvUFJIvRkfFs",
        "colab_type": "code",
        "outputId": "90ea42a9-3652-4ecc-cf39-981b75cf224e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "checkpoint_dir = \"gs://alaeddinselcukgurel/bert/models/sentence_classification/model.ckpt-500\"\n",
        "\n",
        "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "\n",
        "\n",
        "\n",
        "num_train_steps = int(\n",
        "    len(train_examples) / TRAIN_BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
        "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
        "\n",
        "model_fn = run_classifier.model_fn_builder(\n",
        "    bert_config=modeling.BertConfig.from_json_file(CONFIG_FILE),\n",
        "    num_labels=len(label_list),\n",
        "    init_checkpoint=checkpoint_dir,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    num_train_steps=num_train_steps,\n",
        "    num_warmup_steps=num_warmup_steps,\n",
        "    use_tpu=True,\n",
        "    use_one_hot_embeddings=True)\n",
        "\n",
        "estimator = tf.contrib.tpu.TPUEstimator(\n",
        "    use_tpu=True,\n",
        "    model_fn=model_fn,\n",
        "    config=run_config,\n",
        "    train_batch_size=TRAIN_BATCH_SIZE,\n",
        "    eval_batch_size=EVAL_BATCH_SIZE,\n",
        "    predict_batch_size=EVAL_BATCH_SIZE)\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0731 20:03:38.271130 140432068097920 estimator.py:1984] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fb89a850510>) includes params argument, but params are not passed to Estimator.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDQpMml8A24m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "EVALUATION_SENTENCES_DIR = \"/content/drive/My Drive/samplesforbert/guardian_sample_with_annotations.csv\"\n",
        "\n",
        "evaluation_sentences = pd.read_csv(EVALUATION_SENTENCES_DIR, header=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVV3JO1BnJ4A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PREDICT_BATCH_SIZE = 8\n",
        "def getPrediction(in_sentences):\n",
        "  labels = [\"0\", \"1\"]\n",
        "  input_examples = [run_classifier.InputExample(guid=\"\", text_a = x, text_b = None, label = 0) for x in in_sentences] # here, \"\" is just a dummy label\n",
        "  input_features = run_classifier.convert_examples_to_features(input_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "  predict_input_fn = run_classifier.input_fn_builder(features=input_features, seq_length=MAX_SEQ_LENGTH, is_training=False, drop_remainder=True)\n",
        "  predictions = estimator.predict(predict_input_fn)\n",
        "  return predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ru8jw_ZxCRa-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_sent = evaluation_sentences['text']\n",
        "test_sent = test_sent.dropna()\n",
        "result = getPrediction(test_sent)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gq_6O90-pKPC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#SENTENCE PREDICTION\n",
        "import nltk\n",
        "nltk.download(\"popular\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYRs0syA1TeZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "83b50c4b-b774-41a6-c293-0f18582c19da"
      },
      "source": [
        "len(evaluation_sentences)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9P50phoo3gN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "76f0ad84-ede6-44fa-acc0-9b4f8be424ba"
      },
      "source": [
        "test_sent = evaluation_sentences['text']\n",
        "test_sent = test_sent.dropna()\n",
        "#evaluation_sentences = evaluation_sentences.dropna()\n",
        "#result_list = []\n",
        "texts_and_urls = pd.DataFrame(columns= [\"url\", \"sentence\"])\n",
        "for idx, doc in evaluation_sentences.iterrows():\n",
        "  url = doc.url\n",
        "  for elem in nltk.sent_tokenize(doc.text):\n",
        "    texts_and_urls = texts_and_urls.append({\"url\": url, \"sentence\": elem}, ignore_index=True)\n",
        "\"\"\"  tokenized_sentences = nltk.sent_tokenize(doc)\n",
        "  tokenized_results = getPrediction(tokenized_sentences)\n",
        "  result_list.append(tokenized_results)\"\"\""
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'  tokenized_sentences = nltk.sent_tokenize(doc)\\n  tokenized_results = getPrediction(tokenized_sentences)\\n  result_list.append(tokenized_results)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHPFfiF22LaJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result = getPrediction(texts_and_urls.sentence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPmxJZm-G2f0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1b5579b9-7690-4d9c-a1cd-1bf4d92c500b"
      },
      "source": [
        "len(texts_and_urls.sentence)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15033"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhAhwxs8yBJu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#SENTENCE PREDICTION\n",
        "num_actual_predict_examples = len(texts_and_urls)\n",
        "output_predict_file = os.path.join(OUTPUT_DIR, \"test_results.tsv\")\n",
        "pred_labels = []\n",
        "pred_probs = []\n",
        "with tf.io.gfile.GFile(output_predict_file, \"w\") as writer:\n",
        "  num_written_lines = 0\n",
        "  tf.logging.info(\"***** Predict results *****\")\n",
        "  for (i, prediction) in enumerate(result):\n",
        "    probabilities = prediction[\"probabilities\"]\n",
        "    probabilitieslist = list(probabilities)\n",
        "    pred_probs.append(probabilitieslist)\n",
        "    if i >= num_actual_predict_examples:\n",
        "      break\n",
        "    label = str(probabilitieslist.index(max(probabilities))) # 0 1 or 2\n",
        "    pred_labels.append(label)\n",
        "#   output_line = label + \"\\t\" + \"\\t\".join(\n",
        "#       str(class_probability)\n",
        "#       for class_probability in probabilities) + \"\\t\"+ test_sent[i] + \"\\n\" \n",
        "#   writer.write(output_line)\n",
        "#   if label == \"2\": print(output_line)\n",
        "    num_written_lines += 1\n",
        "#assert num_written_lines == num_actual_predict_examples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_fYI3mm3gB1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "texts_and_urls['bert_setence_pred'] = pred_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSOkxyiyGA30",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4afe7399-7c04-4021-d5cd-f824c7bf5fbb"
      },
      "source": [
        "texts_and_urls"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>url</th>\n",
              "      <th>sentence</th>\n",
              "      <th>bert_setence_pred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://content.guardianapis.com/society/2008/...</td>\n",
              "      <td>The annual Mills Regeneration Conference has b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://content.guardianapis.com/society/2008/...</td>\n",
              "      <td>In the early 1990s, the first conference was h...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://content.guardianapis.com/society/2008/...</td>\n",
              "      <td>As the decade progressed, more and more mills ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://content.guardianapis.com/society/2008/...</td>\n",
              "      <td>The conferences after Hebden Bridge visited mi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://content.guardianapis.com/society/2008/...</td>\n",
              "      <td>Now in 2008, with the impact of the credit cru...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>https://content.guardianapis.com/society/2008/...</td>\n",
              "      <td>The north's top 10 1 Salts Mill Salts Mill in ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>https://content.guardianapis.com/society/2008/...</td>\n",
              "      <td>A vast complex of more than one million square...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>https://content.guardianapis.com/society/2008/...</td>\n",
              "      <td>The late Jonathan Silver, a Bradford born entr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>https://content.guardianapis.com/society/2008/...</td>\n",
              "      <td>Mills hadn't been used as galleries, but the t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>https://content.guardianapis.com/society/2008/...</td>\n",
              "      <td>Layers of dull cream and blue paint was remove...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>https://content.guardianapis.com/society/2008/...</td>\n",
              "      <td>The gallery was an instant success.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>https://content.guardianapis.com/society/2008/...</td>\n",
              "      <td>The space has also been used by Pace Electroni...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>https://content.guardianapis.com/society/2008/...</td>\n",
              "      <td>Now, Salts is a hive of life every day except ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>https://content.guardianapis.com/society/2008/...</td>\n",
              "      <td>2 Dean Clough Dean Clough in Halifax is called...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>https://content.guardianapis.com/society/2008/...</td>\n",
              "      <td>The size of a London suburb, Dean Clough was o...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>https://content.guardianapis.com/society/2008/...</td>\n",
              "      <td>When the carpet business closed in the early 1...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>https://content.guardianapis.com/society/2008/...</td>\n",
              "      <td>Sir Ernest Hall was the brains behind the tran...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>https://content.guardianapis.com/society/2008/...</td>\n",
              "      <td>After 20, there is still empty space waiting f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>https://content.guardianapis.com/society/2008/...</td>\n",
              "      <td>3 Listers Mill Listers Mill in Bradford is ano...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>https://content.guardianapis.com/society/2008/...</td>\n",
              "      <td>It is steeped in history, notably the famous M...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>https://content.guardianapis.com/society/2008/...</td>\n",
              "      <td>Readers of Peter Wright's book, Spycatcher, wi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>https://content.guardianapis.com/society/2008/...</td>\n",
              "      <td>That building we believe was Prospect House, o...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>https://content.guardianapis.com/society/2008/...</td>\n",
              "      <td>It was sold along with all the other assets un...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>https://content.guardianapis.com/society/2008/...</td>\n",
              "      <td>The mill was stripped, there were fires and ev...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>https://content.guardianapis.com/society/2008/...</td>\n",
              "      <td>Manchester-based Urban Splash rose to the chal...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>https://content.guardianapis.com/society/2008/...</td>\n",
              "      <td>4 Victoria Mills Victoria Mills in Saltaire (i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>https://content.guardianapis.com/society/2008/...</td>\n",
              "      <td>They had come to Bradford from Limerick, Irela...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>https://content.guardianapis.com/society/2008/...</td>\n",
              "      <td>After textiles finished, the mill was sold to ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>https://content.guardianapis.com/society/2008/...</td>\n",
              "      <td>In a stunning conversion into more than 400 ap...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>https://content.guardianapis.com/society/2008/...</td>\n",
              "      <td>Converted to an amazingly high spec, with tenn...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15003</th>\n",
              "      <td>https://content.guardianapis.com/world/2003/au...</td>\n",
              "      <td>Shia Muslim clerics were at the scene, on Saad...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15004</th>\n",
              "      <td>https://content.guardianapis.com/world/2003/au...</td>\n",
              "      <td>Hundreds also marched on the headquarters of t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15005</th>\n",
              "      <td>https://content.guardianapis.com/world/2003/au...</td>\n",
              "      <td>The Navy said yesterday it had intercepted a s...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15006</th>\n",
              "      <td>https://content.guardianapis.com/world/2003/au...</td>\n",
              "      <td>Royal Marine commandos from HMS Sutherland boa...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15007</th>\n",
              "      <td>https://content.guardianapis.com/world/2003/au...</td>\n",
              "      <td>'This is the most significant seizure we have ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15008</th>\n",
              "      <td>https://content.guardianapis.com/world/2003/au...</td>\n",
              "      <td>The US administrator in Iraq, Paul Bremer, sai...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15009</th>\n",
              "      <td>https://content.guardianapis.com/world/2003/au...</td>\n",
              "      <td>'The seizure of the Navstar 1 demonstrates the...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15010</th>\n",
              "      <td>https://content.guardianapis.com/world/2003/au...</td>\n",
              "      <td>Earlier in the week, US authorities seized 12 ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15011</th>\n",
              "      <td>https://content.guardianapis.com/world/2003/au...</td>\n",
              "      <td>Damage to Iraq's major northern oil pipeline h...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15012</th>\n",
              "      <td>https://content.guardianapis.com/football/2000...</td>\n",
              "      <td>UEFA today warned England could be thrown out ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15013</th>\n",
              "      <td>https://content.guardianapis.com/football/2000...</td>\n",
              "      <td>European football's government body this eveni...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15014</th>\n",
              "      <td>https://content.guardianapis.com/football/2000...</td>\n",
              "      <td>Addressing a press conference after the emerge...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15015</th>\n",
              "      <td>https://content.guardianapis.com/football/2000...</td>\n",
              "      <td>Hundreds of English fans were arrested in clas...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15016</th>\n",
              "      <td>https://content.guardianapis.com/football/2000...</td>\n",
              "      <td>Most of them have been expelled.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15017</th>\n",
              "      <td>https://content.guardianapis.com/football/2000...</td>\n",
              "      <td>UEFA President Lennart Johansson described the...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15018</th>\n",
              "      <td>https://content.guardianapis.com/football/2000...</td>\n",
              "      <td>Director of Euro 2000 Alain Courtois has also ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15019</th>\n",
              "      <td>https://content.guardianapis.com/football/2000...</td>\n",
              "      <td>\"I will make three simple statements.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15020</th>\n",
              "      <td>https://content.guardianapis.com/football/2000...</td>\n",
              "      <td>The first is that the British government did n...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15021</th>\n",
              "      <td>https://content.guardianapis.com/football/2000...</td>\n",
              "      <td>This is a huge shortcoming,\" Courtois said.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15022</th>\n",
              "      <td>https://content.guardianapis.com/football/2000...</td>\n",
              "      <td>\"When I see what the German government and Foo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15023</th>\n",
              "      <td>https://content.guardianapis.com/football/2000...</td>\n",
              "      <td>\"Whereas on the other side (Britain), nothing ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15024</th>\n",
              "      <td>https://content.guardianapis.com/football/2000...</td>\n",
              "      <td>It is not right that 14 extremely dangerous ho...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15025</th>\n",
              "      <td>https://content.guardianapis.com/football/2000...</td>\n",
              "      <td>\"I would also like to point out certain partie...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15026</th>\n",
              "      <td>https://content.guardianapis.com/football/2000...</td>\n",
              "      <td>There were cameras situated specifically in Ch...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15027</th>\n",
              "      <td>https://content.guardianapis.com/football/2000...</td>\n",
              "      <td>\"Finally, what the Belgian authorities have do...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15028</th>\n",
              "      <td>https://content.guardianapis.com/football/2000...</td>\n",
              "      <td>By that I mean stopping potential troublemaker...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15029</th>\n",
              "      <td>https://content.guardianapis.com/football/2000...</td>\n",
              "      <td>\"How these people can leave an island, we are ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15030</th>\n",
              "      <td>https://content.guardianapis.com/football/2000...</td>\n",
              "      <td>Obviously there has to have been a very lax at...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15031</th>\n",
              "      <td>https://content.guardianapis.com/football/2000...</td>\n",
              "      <td>\"They said they had made plans and forged a la...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15032</th>\n",
              "      <td>https://content.guardianapis.com/football/2000...</td>\n",
              "      <td>Well if this is their plan, bravo,\" concluded ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15033 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     url  ... bert_setence_pred\n",
              "0      https://content.guardianapis.com/society/2008/...  ...                 0\n",
              "1      https://content.guardianapis.com/society/2008/...  ...                 0\n",
              "2      https://content.guardianapis.com/society/2008/...  ...                 0\n",
              "3      https://content.guardianapis.com/society/2008/...  ...                 0\n",
              "4      https://content.guardianapis.com/society/2008/...  ...                 0\n",
              "5      https://content.guardianapis.com/society/2008/...  ...                 0\n",
              "6      https://content.guardianapis.com/society/2008/...  ...                 0\n",
              "7      https://content.guardianapis.com/society/2008/...  ...                 0\n",
              "8      https://content.guardianapis.com/society/2008/...  ...                 0\n",
              "9      https://content.guardianapis.com/society/2008/...  ...                 0\n",
              "10     https://content.guardianapis.com/society/2008/...  ...                 0\n",
              "11     https://content.guardianapis.com/society/2008/...  ...                 0\n",
              "12     https://content.guardianapis.com/society/2008/...  ...                 0\n",
              "13     https://content.guardianapis.com/society/2008/...  ...                 0\n",
              "14     https://content.guardianapis.com/society/2008/...  ...                 0\n",
              "15     https://content.guardianapis.com/society/2008/...  ...                 0\n",
              "16     https://content.guardianapis.com/society/2008/...  ...                 0\n",
              "17     https://content.guardianapis.com/society/2008/...  ...                 0\n",
              "18     https://content.guardianapis.com/society/2008/...  ...                 0\n",
              "19     https://content.guardianapis.com/society/2008/...  ...                 0\n",
              "20     https://content.guardianapis.com/society/2008/...  ...                 0\n",
              "21     https://content.guardianapis.com/society/2008/...  ...                 0\n",
              "22     https://content.guardianapis.com/society/2008/...  ...                 0\n",
              "23     https://content.guardianapis.com/society/2008/...  ...                 0\n",
              "24     https://content.guardianapis.com/society/2008/...  ...                 0\n",
              "25     https://content.guardianapis.com/society/2008/...  ...                 0\n",
              "26     https://content.guardianapis.com/society/2008/...  ...                 1\n",
              "27     https://content.guardianapis.com/society/2008/...  ...                 0\n",
              "28     https://content.guardianapis.com/society/2008/...  ...                 0\n",
              "29     https://content.guardianapis.com/society/2008/...  ...                 0\n",
              "...                                                  ...  ...               ...\n",
              "15003  https://content.guardianapis.com/world/2003/au...  ...                 1\n",
              "15004  https://content.guardianapis.com/world/2003/au...  ...                 1\n",
              "15005  https://content.guardianapis.com/world/2003/au...  ...                 0\n",
              "15006  https://content.guardianapis.com/world/2003/au...  ...                 0\n",
              "15007  https://content.guardianapis.com/world/2003/au...  ...                 0\n",
              "15008  https://content.guardianapis.com/world/2003/au...  ...                 0\n",
              "15009  https://content.guardianapis.com/world/2003/au...  ...                 0\n",
              "15010  https://content.guardianapis.com/world/2003/au...  ...                 0\n",
              "15011  https://content.guardianapis.com/world/2003/au...  ...                 0\n",
              "15012  https://content.guardianapis.com/football/2000...  ...                 0\n",
              "15013  https://content.guardianapis.com/football/2000...  ...                 0\n",
              "15014  https://content.guardianapis.com/football/2000...  ...                 0\n",
              "15015  https://content.guardianapis.com/football/2000...  ...                 1\n",
              "15016  https://content.guardianapis.com/football/2000...  ...                 0\n",
              "15017  https://content.guardianapis.com/football/2000...  ...                 0\n",
              "15018  https://content.guardianapis.com/football/2000...  ...                 0\n",
              "15019  https://content.guardianapis.com/football/2000...  ...                 0\n",
              "15020  https://content.guardianapis.com/football/2000...  ...                 0\n",
              "15021  https://content.guardianapis.com/football/2000...  ...                 0\n",
              "15022  https://content.guardianapis.com/football/2000...  ...                 0\n",
              "15023  https://content.guardianapis.com/football/2000...  ...                 0\n",
              "15024  https://content.guardianapis.com/football/2000...  ...                 0\n",
              "15025  https://content.guardianapis.com/football/2000...  ...                 0\n",
              "15026  https://content.guardianapis.com/football/2000...  ...                 0\n",
              "15027  https://content.guardianapis.com/football/2000...  ...                 0\n",
              "15028  https://content.guardianapis.com/football/2000...  ...                 0\n",
              "15029  https://content.guardianapis.com/football/2000...  ...                 0\n",
              "15030  https://content.guardianapis.com/football/2000...  ...                 0\n",
              "15031  https://content.guardianapis.com/football/2000...  ...                 0\n",
              "15032  https://content.guardianapis.com/football/2000...  ...                 0\n",
              "\n",
              "[15033 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nLce8lE7bji",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for (i, prediction) in enumerate(result):\n",
        "  probabilities = prediction[\"probabilities\"]\n",
        "  probabilitieslist = list(probabilities)\n",
        "  pred_probs.append(probabilitieslist)\n",
        "  if i >= num_actual_predict_examples:\n",
        "    break\n",
        "  label = str(probabilitieslist.index(max(probabilities))) # 0 1 or 2\n",
        "  print(label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XBJDjcbCylt",
        "colab_type": "code",
        "outputId": "28ba10b6-7e9e-41df-bcbc-3ed0541898c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(result_list)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4765"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8ZNzLcQD2ai",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "outputId": "031f0bde-4771-4224-9266-94e594fc0363"
      },
      "source": [
        "\n",
        "num_actual_predict_examples = len(test_sent)\n",
        "output_predict_file = os.path.join(OUTPUT_DIR, \"test_results.tsv\")\n",
        "pred_labels = []\n",
        "pred_probs = []\n",
        "with tf.io.gfile.GFile(output_predict_file, \"w\") as writer:\n",
        "  num_written_lines = 0\n",
        "  tf.logging.info(\"***** Predict results *****\")\n",
        "  for (i, prediction) in enumerate(result):\n",
        "    probabilities = prediction[\"probabilities\"]\n",
        "    probabilitieslist = list(probabilities)\n",
        "    pred_probs.append(probabilitieslist)\n",
        "    if i >= num_actual_predict_examples:\n",
        "      break\n",
        "    label = str(probabilitieslist.index(max(probabilities))) # 0 1 or 2\n",
        "    pred_labels.append(label)\n",
        "#   output_line = label + \"\\t\" + \"\\t\".join(\n",
        "#       str(class_probability)\n",
        "#       for class_probability in probabilities) + \"\\t\"+ test_sent[i] + \"\\n\" \n",
        "#   writer.write(output_line)\n",
        "#   if label == \"2\": print(output_line)\n",
        "    num_written_lines += 1\n",
        "#assert num_written_lines == num_actual_predict_examples"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-140-446d39139342>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"***** Predict results *****\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mprobabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"probabilities\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mprobabilitieslist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobabilities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mpred_probs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobabilitieslist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEASc4Pu75OJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "76ccf50d-36d5-4445-e374-051b7a3f14d4"
      },
      "source": [
        "pred_labels"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtyuhaTvHxaN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for (i, prediction) in enumerate(result):\n",
        "    probabilities = prediction[\"probabilities\"]\n",
        "    print(probabilities)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIGrvgmaHELy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_labels_int = [int(i) for i in pred_labels]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AI4JqW-HRp5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame()\n",
        "df['text'] = test_sent\n",
        "df['label'] = pred_labels_int\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-3FVXB9T9BS",
        "colab_type": "code",
        "outputId": "fdb7f49d-75ec-48df-ab27-3e936c9def67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(test_sent)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4765"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQTHohfLHSgy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.to_csv(\"bertdocumentpredictions.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLndoe8TQzQ7",
        "colab_type": "code",
        "outputId": "96e064ca-8a52-45db-83e4-8730a7c6b47b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('drive')\n",
        "\n",
        "df.to_csv('allbertpredictions.csv')\n",
        "!cp allbertpredictions.csv drive/My\\ Drive/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at drive; to attempt to forcibly remount, call drive.mount(\"drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdwsOAkUSlwp",
        "colab_type": "code",
        "outputId": "a7ced20a-fea4-43b4-e312-19c7854cb245",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"files.download('df.csv')\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "files.download('df.csv')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDpTvp5ElwC1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_df = pd.DataFrame()\n",
        "new_df['url'] = evaluation_sentences['url']\n",
        "new_df['text'] = evaluation_sentences['text']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NSj7B9Ul-5I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_df = new_df.dropna()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLfOhJ-UmGsk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0nj9xiomAT1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "exporting_df = pd.DataFrame()\n",
        "exporting_df['url'] = new_df['url']\n",
        "exporting_df['text'] = new_df['text']\n",
        "exporting_df['label'] = pred_labels_int"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0XGG4b6mccw",
        "colab_type": "code",
        "outputId": "71b5b40f-190d-46f0-89df-049701e24793",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('drive')\n",
        "\n",
        "exporting_df.to_csv('bertdocumentpredictionsurl.csv')\n",
        "!cp bertdocumentpredictionsurl.csv drive/My\\ Drive/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at drive; to attempt to forcibly remount, call drive.mount(\"drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-jVibH1mka9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "a87fc2b8-d6bb-45fb-a558-49a9e57ad631"
      },
      "source": [
        "import pickle\n",
        "\n",
        "with open('result_lists.pkl', 'wb') as f:\n",
        "  pickle.dump(result_list, f)\n"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-b03dcd702ca6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'result_lists.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: can't pickle generator objects"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvIUQ3M6Ixu1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dec78cc2-225c-4900-9f0f-c8f097210aed"
      },
      "source": [
        "type(result_list)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufAHC26dIzO-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "55cf9faa-5698-40d3-8494-128d5fcc75dd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('drive')\n",
        "\n",
        "texts_and_urls.to_csv('sentence_predictions.csv')\n",
        "!cp sentence_predictions.csv drive/My\\ Drive/"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at drive; to attempt to forcibly remount, call drive.mount(\"drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVskbKcWW5rr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "558f60a2-5000-4a66-d608-0a66fd6cf693"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('drive')\n",
        "\n",
        "texts_and_urls.to_csv('india_sentence_predictions.csv')\n",
        "!cp india_sentence_predictions.csv drive/My\\ Drive/"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at drive; to attempt to forcibly remount, call drive.mount(\"drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}